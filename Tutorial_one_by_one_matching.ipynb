{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d59e3-83d1-478d-8813-537b2778d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Modules\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.linalg import expm, cholesky\n",
    "from numpy.linalg import inv, det\n",
    "import scipy\n",
    "import ot\n",
    "import itertools\n",
    "import os\n",
    "from scipy.stats import multivariate_normal\n",
    "from untils import *\n",
    "from alg_tools import *\n",
    "from evaluation_metric import *\n",
    "from scipy.linalg import block_diag\n",
    "from scipy.special import logsumexp as lse\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.pyplot import cm\n",
    "import timeit\n",
    "np.random.seed(42)\n",
    "G_data_list = ['Tris_data','Nbody_data','1dGP_data','2dGP_data']\n",
    "exp_index = 1 #change this index to reproduce results on different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb7c239-f23a-48c8-a726-25f36195975a",
   "metadata": {},
   "source": [
    "# Parameter Setting (Tunable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d2ed0-690f-4dab-b9da-86432266449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DFPL = {'Mi_1.5':[[32],[12],[200],[32]], #Default Mi list for each experiement when nu = 1.5\n",
    "        'Mi_2.5':[[8,4],[4,3],[40,5],[8,4]], #Default Mi list for each experiement when nu = 2.5\n",
    "        'c':[1,4,1,1], #Default c list for each experiement when nu = 2.5\n",
    "       }\n",
    "max_iter = 5 #number of iterations of message passing\n",
    "t_end = 2 #end time\n",
    "nu = 1.5 #order of matern kernel 1.5 or 2.5\n",
    "l = 3 #length parameter for matern kernel default: 3 for nu=1.5, 2 for nu=2.5\n",
    "samples_pre_compute = 20 #number of samples used for approximation of the precomputation tensor \\Gamma\n",
    "\n",
    "#-------------------------parameters--for--sampling--trajectories--------------------------------#\n",
    "n_trajectories = 50 #number of trajectories to sample for each starting observation\n",
    "load_newest = False #load the newest message or load the message with the smallest norm changes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b7b68-644f-451d-aed5-26a55261ca15",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93781784-1798-4698-9269-73f8bdf33da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset to reproduce results 0-3\n",
    "G_data = G_data_list[exp_index]\n",
    "\n",
    "GD = np.load('G_data/{}.npz'.format(G_data))['arr_0']\n",
    "\n",
    "if len(GD.shape) == 2:\n",
    "    GD = np.expand_dims(GD,axis=-1)\n",
    "T,N,data_D = GD.shape[0]-1,GD.shape[1], GD.shape[2]\n",
    "print('Timestep:{},Number of observations:{},dimension:{}'.format(T-1,N,data_D))\n",
    "#Parameter Setting\n",
    "n=N\n",
    "\n",
    "lo = False\n",
    "dt_list = [0]\n",
    "lot = 3\n",
    "if not lo:\n",
    "    dt_list = np.linspace(0,t_end,T+1)\n",
    "    D = GD+0\n",
    "else:\n",
    "    dt_list = np.concatenate([np.linspace(0,t_end,T+1)[0:lot-1],np.linspace(0,t_end,T+1)[lot:]],axis=0)\n",
    "    D = np.concatenate([GD[0:lot-1],GD[lot:]],axis=0)\n",
    "    T -= 1\n",
    "\n",
    "color_ob = cm.hot(np.linspace(0,1,T+2))\n",
    "\n",
    "if data_D >= 2:\n",
    "    for i in range(T+1):\n",
    "        plt.scatter(D[i,:,0],D[i,:,1],color=color_ob[i],label=str(i))\n",
    "        plt.xlabel('Dim 1')\n",
    "        plt.ylabel('Dim 2')\n",
    "else:\n",
    "    for i in range(N):\n",
    "        plt.plot([t for t in range(T+1)],D[:,i,0],label=str(i))\n",
    "        plt.scatter([t for t in range(T+1)],D[:,i,0],label=str(i))\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('Position X')\n",
    "print('Data loaded successfully! Visualization of ground truth:')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb0a2f-a955-488d-8ba0-8dc0095ba286",
   "metadata": {},
   "source": [
    "# Precomputation Stage (no need to tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b2752-b06f-471b-8140-a0eb4e8dc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting parameters\n",
    "save_name = G_data[:-5]\n",
    "c = DFPL['c'][exp_index]\n",
    "save_dir = 'Experiments/{}_c={}_nu={}'.format(save_name,c,nu)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "if nu == 1.5:\n",
    "    Mi_list = DFPL['Mi_1.5'][exp_index]\n",
    "    total_indices = [Mi_list for dim in range(data_D)]\n",
    "    d = 2\n",
    "    lam = np.sqrt(2*nu)/l\n",
    "    A = np.zeros((d,d))\n",
    "    for i in range(d-1):\n",
    "        A[i,i+1] = 1\n",
    "    A[d-1,0] = -lam**2\n",
    "    A[d-1,1] = -2*lam\n",
    "    L = np.zeros((d,1))\n",
    "    q_list =[]\n",
    "    for dim in range(data_D):\n",
    "        \n",
    "        sigma = np.sqrt(np.var(D[:,:,dim]))*c\n",
    "        q_list.append(2*(sigma**2)*np.sqrt(np.pi)*scipy.special.gamma(nu+0.5)*lam**(2*nu)/scipy.special.gamma(nu))\n",
    "    L[-1,0] = 1\n",
    "    mu_0_list = []\n",
    "    sigma_0_list = []\n",
    "    for dim in range(data_D):\n",
    "        mu_0 = np.zeros(d)\n",
    "        sigma_0  = solve_stationary(A,q_list[dim]).reshape((d,d))\n",
    "        mu_0_list.append(mu_0)\n",
    "        sigma_0_list.append(sigma_0)\n",
    "elif nu == 2.5:\n",
    "    Mi_list = DFPL['Mi_2.5'][exp_index]\n",
    "    total_indices = [Mi_list for dim in range(data_D)]\n",
    "    d = 3\n",
    "    lam = np.sqrt(2*nu)/l\n",
    "    A = np.zeros((d,d))\n",
    "    for i in range(d-1):\n",
    "        A[i,i+1] = 1\n",
    "    A[d-1,0] = -lam**3\n",
    "    A[d-1,1] = -3*lam**2\n",
    "    A[d-1,2] = -3*lam\n",
    "    \n",
    "    L = np.zeros((d,1))\n",
    "    q_list =[]\n",
    "    for dim in range(data_D):\n",
    "        \n",
    "        sigma = np.sqrt(np.var(D[:,:,dim]))*c\n",
    "        q_list.append(2*(sigma**2)*np.sqrt(np.pi)*scipy.special.gamma(nu+0.5)*lam**(2*nu)/scipy.special.gamma(nu))\n",
    "    L[-1,0] = 1\n",
    "    mu_0_list = []\n",
    "    sigma_0_list = []\n",
    "    for dim in range(data_D):\n",
    "        mu_0 = np.zeros(d)\n",
    "        sigma_0  = solve_stationary(A,q_list[dim]).reshape((d,d))\n",
    "        mu_0_list.append(mu_0)\n",
    "        sigma_0_list.append(sigma_0)\n",
    "else:\n",
    "    raise Exception(\"Set nu to be 1.5 or 2.5!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ac72a-a90f-42a6-8d6f-c452ce44ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "cond_mean_list = []\n",
    "cond_cov_list = [[] for dim in range(data_D)]\n",
    "cov_list = [[] for dim in range(data_D)]\n",
    "Kp = np.prod(total_indices[0])\n",
    "cond_mean_margin = np.zeros((data_D,T,N,d-1))\n",
    "cond_cov_margin_list = [[] for dim in range(data_D)]\n",
    "cond_mean_margin = np.zeros((data_D,T,N,d-1))\n",
    "for dim in range(data_D):\n",
    "    COV_X_list = []\n",
    "    COV_XY_list = []\n",
    "    for i in range(T):\n",
    "        Cov = compute_cov_explicit(A, L, q_list[dim], dt_list[i], dt_list[i+1],sigma_0_list[dim])\n",
    "        cov_list[dim].append(Cov)\n",
    "        s_Cov = Cov[index_perm(d), :][:, index_perm(d)]\n",
    "        COV_X = s_Cov[0:2, 0:2]\n",
    "        COV_Y = s_Cov[2:2*d, 2:2*d]\n",
    "        COV_XY = s_Cov[0:2, 2:2*d]\n",
    "        cond_COV = COV_Y - COV_XY.T @ np.linalg.inv(COV_X) @ COV_XY\n",
    "        cond_cov_list[dim].append(cond_COV)\n",
    "        COV_X_list.append(COV_X+0)\n",
    "        COV_XY_list.append(COV_XY+0)\n",
    "        cond_cov_margin = Cov[1:d,1:d] - Cov[1:d,0:1] @ Cov[0:1,1:d] /Cov[0,0]\n",
    "        cond_cov_margin_list[dim].append(cond_cov_margin)\n",
    "        for j in range(N):\n",
    "            x_t = D[i,j,dim]\n",
    "            cond_mean_margin[dim,i,j,:] = -Cov[1:d,0]/Cov[0,0]*D[i,j,dim]\n",
    "    cond_Means = compute_conditional_mean(np.stack(COV_X_list,axis=0), np.stack(COV_XY_list,axis=0), D[:,:,dim], d)\n",
    "    cond_mean_list.append(cond_Means)\n",
    "\n",
    "print('Precomputation for Gamma tensor start!')\n",
    "phi_phi_pdf_list = []\n",
    "Kp = [np.prod(total_indices[dim]) for dim in range(data_D)]\n",
    "for dim in range(data_D):\n",
    "    print('Computing for dimension {}'.format(dim))\n",
    "    phi_save_dir = save_dir+'/joint_phi_phi_{}'.format(dim)\n",
    "    phi_phi_pdf = wave_pdf(T,N,total_indices[dim],d,cov_list[dim],cond_cov_list[dim],cond_mean_list[dim],cond_cov_margin_list[dim],cond_mean_margin[dim],phi_save_dir,samples_pre_compute)\n",
    "    phi_phi_pdf_list.append(phi_phi_pdf)\n",
    "\n",
    "\n",
    "final_phi_phi_list = []\n",
    "for dim in range(data_D):\n",
    "    print('Saving precomputation tensor for dimension {} to {}'.format(dim,save_dir+'/final_phi_{}.npz'))\n",
    "    Cond_xx = condition_xx(D[:,:,dim],cov_list[dim],d)\n",
    "    final_phi_phi_list.append(phi_phi_pdf_list[dim] + Cond_xx.reshape((T,N,N,1,1)))\n",
    "    np.savez(save_dir+'/final_phi_{}.npz'.format(dim),final_phi_phi_list[dim])\n",
    "\n",
    "print('Precomputation done! Time spent: {} seconds'.format(timeit.default_timer()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692783a-a6f8-4f22-b12d-59300df62c10",
   "metadata": {},
   "source": [
    "# Message Passing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed597ef0-ee57-48f2-afbf-411536294abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization\n",
    "phi_phi_list = []\n",
    "print('Loading precompuated tensor')\n",
    "start = timeit.default_timer()\n",
    "for i in range(data_D):\n",
    "    phi_phi_list.append(np.load((save_dir+'/final_phi_{}.npz'.format(i)))['arr_0'])\n",
    "print('Loading done!')\n",
    "save_freq = 1\n",
    "error_thre = 1e-10\n",
    "errors = message_passing(phi_phi_list,data_D,T,N,total_indices,max_iter,save_dir,save_freq,error_thre)\n",
    "print('Message passing done! Time spent: {} seconds'.format(timeit.default_timer()-start))\n",
    "\n",
    "plt.plot([i+1 for i in range(max_iter)],errors)\n",
    "plt.title('Norm changes in messages against iterations')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7501c0-4509-4025-98f8-8c24fa9b4f84",
   "metadata": {},
   "source": [
    "# Generating Trajectories\n",
    "The following only matches observations, matched observations are connected by straight lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d797c7b-d4b8-477b-b8d8-a8e86387ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trajectories_sample(C_z_right,C_z_left,phi_phi_list,data_D,T,N,Kp_shape,sample,save_traj_dir):\n",
    "    n = N \n",
    "    t=0\n",
    "    C_z_right_t = C_z_right[t].reshape(N,-1)\n",
    "    C_z_left_t = C_z_left[t].reshape(N,-1)\n",
    "    C_z_right_left_t = C_z_right_t.reshape((N,1,-1,1)) + C_z_left_t.reshape((1,N,1,-1))\n",
    "    Kpp = Kp_shape[0]\n",
    "    Kp = np.prod(Kp_shape)\n",
    "    if data_D > 1:\n",
    "        for dim in range(data_D-1):\n",
    "            Kpp *= Kp_shape[dim+1]\n",
    "            if dim == 0:\n",
    "                phi_phi_expand_t = (np.expand_dims(phi_phi_list[dim][t],axis=(-3,-1))+np.expand_dims(phi_phi_list[dim+1][t],axis=(-4,-2))).reshape(N,N,Kpp,Kpp)\n",
    "            else:\n",
    "                phi_phi_expand_t = (np.expand_dims(phi_phi_expand_t,axis=(-3,-1))+np.expand_dims(phi_phi_list[dim+1][t],axis=(-4,-2))).reshape(N,N,Kpp,Kpp)\n",
    "        joint_d_t = phi_phi_expand_t+C_z_right_left_t\n",
    "    else:\n",
    "        joint_d_t = phi_phi_list[0][t]+C_z_right_left_t\n",
    "    total_yt_index_recorder = np.zeros((sample*n,T+1)).astype('int')\n",
    "    total_trajectory = np.zeros((sample*n,T+1)).astype('int')\n",
    "    for tt in range(sample*n):\n",
    "        total_trajectory[tt,0] = tt//sample\n",
    "    xt_index = total_trajectory[:,0].astype('int')\n",
    "    print('Generating velocity for initial observations')\n",
    "    yt_index = sample_yt1_ini_sample_log_md_sample(joint_d_t,n,sample).astype('int')\n",
    "    for t in range(T):\n",
    "        print('Matching observations for time step {}'.format(t))\n",
    "        phi_phi_expand_t = 0\n",
    "        joint_d = 0\n",
    "        C_z_right_left_t = 0\n",
    "        C_z_right_t = C_z_right[t].reshape(N,-1)\n",
    "        C_z_left_t = C_z_left[t].reshape(N,-1)\n",
    "        C_z_right_left_t = C_z_right_t.reshape((N,1,-1,1)) + C_z_left_t.reshape((1,N,1,-1))\n",
    "        Kpp = Kp_shape[0]\n",
    "        if data_D > 1:\n",
    "            for dim in range(data_D-1):\n",
    "                Kpp *= Kp_shape[dim+1]\n",
    "                if dim == 0:\n",
    "                    phi_phi_expand_t = (np.expand_dims(phi_phi_list[dim][t],axis=(-3,-1))+np.expand_dims(phi_phi_list[dim+1][t],axis=(-4,-2))).reshape(N,N,Kpp,Kpp)\n",
    "                else:\n",
    "                    phi_phi_expand_t = (np.expand_dims(phi_phi_expand_t,axis=(-3,-1))+np.expand_dims(phi_phi_list[dim+1][t],axis=(-4,-2))).reshape(N,N,Kpp,Kpp)\n",
    "            joint_d_t = phi_phi_expand_t+C_z_right_left_t\n",
    "        else:\n",
    "            joint_d_t = phi_phi_list[0][t]+C_z_right_left_t\n",
    "        m_t1 = lse(joint_d_t,axis=-1) + 0\n",
    "        yt1_index = np.zeros(sample*n).astype('int')\n",
    "        xt1_index = np.zeros(sample*n).astype('int')\n",
    "        for i in range(sample*n):\n",
    "            B = m_t1[xt_index[i],:,yt_index[i]] + 0\n",
    "            B -= lse(B)\n",
    "            xt1_index[i] = np.random.choice([i for i in range(N)], p = np.exp(B))\n",
    "            yt1_p = joint_d_t[xt_index[i],xt1_index[i],yt_index[i],:] + 0\n",
    "            yt1_p -= lse(yt1_p)\n",
    "            yt1_index[i] = np.random.choice([i for i in range(Kp)], p = np.exp(yt1_p))\n",
    "        total_yt_index_recorder[:,t+1] = yt1_index + 0\n",
    "        total_trajectory[:,t+1] = xt1_index + 0\n",
    "        yt_index = (yt1_index+0).astype('int')\n",
    "        xt_index = (xt1_index+0).astype('int')\n",
    "    print('Saving results to {}'.format(save_traj_dir))\n",
    "    np.savez(save_traj_dir+'/trajectories',np.array(total_trajectory))\n",
    "    np.savez(save_traj_dir+'/y_trajectories',np.array(total_yt_index_recorder))\n",
    "    return np.array(total_trajectory),np.array(total_yt_index_recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b15e4a-70ba-4fd5-9397-3640cd4b96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval Mode\n",
    "save_traj_dir = 'Results/{}_c={}_nu={}'.format(save_name,c,nu)\n",
    "if not os.path.exists(save_traj_dir):\n",
    "    os.mkdir(save_traj_dir)\n",
    "phi_phi_list =[]\n",
    "for i in range(data_D):\n",
    "    phi_phi_list.append(np.load(save_dir+'/final_phi_{}.npz'.format(i))['arr_0'])\n",
    "\n",
    "if not load_newest:\n",
    "    mess_n = '/message_sample_best.npz'\n",
    "else:\n",
    "    mess_n = '/message_sample_new.npz'\n",
    "\n",
    "C_z_left,C_z_right = np.load(save_dir+mess_n)['arr_2'],np.load(save_dir+mess_n)['arr_3']\n",
    "print('Message loaded successfully!')\n",
    "n = N\n",
    "total_yt_index_recorder = []\n",
    "Kp_shape = [np.prod(i) for i in total_indices]\n",
    "\n",
    "print('Start to generate matching of observations')\n",
    "\n",
    "x_traj,y_traj = generate_trajectories_sample(C_z_right,C_z_left,phi_phi_list,data_D,T,N,Kp_shape,n_trajectories,save_traj_dir)\n",
    "\n",
    "color = cm.rainbow(np.linspace(0, 1, N))\n",
    "print('Visualizing Results:')\n",
    "fig,ax = plt.subplots(nrows=1,ncols=2,sharey=True,figsize=(12,5))\n",
    "if data_D > 1:\n",
    "    for i in range(n_trajectories*n):\n",
    "        s_trajectory = x_traj[i,:]\n",
    "        ax[1].plot([D[j,:,0][s_trajectory[j]] for j in range(T+1)],[D[j,:,1][s_trajectory[j]] for j in range(T+1)],linewidth=0.05,c = color[i//n_trajectories])\n",
    "    ax[1].set_title('sampled matching')\n",
    "    \n",
    "    for i in range(n):\n",
    "        ax[0].plot([D[j,i,0] for j in range(T+1)],[D[j,i,1] for j in range(T+1)],linewidth=2,c = color[i])\n",
    "    ax[0].set_title('ground truth') \n",
    "else:\n",
    "    for i in range(N):\n",
    "        ax[0].plot([t for t in range(T+1)],D[:,i,0],label=str(i))\n",
    "        ax[0].scatter([t for t in range(T+1)],D[:,i,0],label=str(i))\n",
    "        ax[0].set_xlabel('t')\n",
    "        ax[0].set_ylabel('Position X')\n",
    "    ax[0].set_title('ground truth') \n",
    "    for i in range(n_trajectories*n):\n",
    "        s_trajectory = x_traj[i,:]\n",
    "        ax[1].plot([i for i in range(T+1)],[D[j,:,0][s_trajectory[j]] for j in range(T+1)],linewidth=0.05,c = color[i//n_trajectories])\n",
    "    ax[1].set_title('sampled matching')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9d43c-f4c8-4cf9-b94d-76808083d40f",
   "metadata": {},
   "source": [
    "# Quantitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca34e9-5151-4f2a-b1c8-14c77523a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_sample = np.empty((x_traj.shape[0]//N, T+1,N))\n",
    "for i in range(x_traj.shape[0]//N):\n",
    "    D_sample[i] = x_traj[np.arange(N) * x_traj.shape[0]//N + i].T\n",
    "D_sample = D_sample.astype(int)\n",
    "eva_results = obo_evaluation(D, D_sample)\n",
    "print('Showing Quantitative Results:')\n",
    "for i in eva_results.keys():\n",
    "    print(i+': '+(\"%.4f\" % float(eva_results[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
